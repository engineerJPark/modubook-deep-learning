{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"colab_05_Sonar_Train_Test.ipynb","provenance":[{"file_id":"13kI1eGznxD8cu3YU-vmjNTDub0GHKtSH","timestamp":1585419824291}],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":76},"id":"iOw6XzF5aC2a","executionInfo":{"status":"ok","timestamp":1624114955087,"user_tz":-540,"elapsed":4715,"user":{"displayName":"공대생지식창고","photoUrl":"","userId":"09343926758650734120"}},"outputId":"dee8a7c6-9dfe-47da-e1ef-ade0bfcf437e"},"source":["# 데이터 입력\n","from google.colab import files\n","uploaded = files.upload()\n","my_data = 'sonar.csv'\n","\n","from keras.models import Sequential\n","from keras.layers.core import Dense\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","import numpy\n","import tensorflow as tf\n","\n","# seed 값 설정\n","seed = 0\n","numpy.random.seed(seed)\n","tf.compat.v1.set_random_seed(3)\n","\n","#데이터 적용\n","df = pd.read_csv(my_data, header=None)\n","\n","'''\n","print(df.info())\n","print(df.head())\n","'''\n","\n","dataset = df.values\n","X = dataset[:,0:60]\n","Y_obj = dataset[:,60]\n","\n","e = LabelEncoder()\n","e.fit(Y_obj)\n","Y = e.transform(Y_obj)"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-fa88c836-e17d-465c-b263-ce047da39650\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-fa88c836-e17d-465c-b263-ce047da39650\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving sonar.csv to sonar (1).csv\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uEByDFuLaGAq"},"source":["sklearn 라이브러리의 train_test_split()함수를 통해서 학습셋과 테스트셋을 쉽게 나눌 수 있다.\n","\n","처음 보는 함수니까 레퍼런스를 살펴보자.\n","https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n","\n","train_test_split(X, Y, test_size=0.3, random_state=seed)\n","에서 X는 속성, Y는 클래스를 넣고, test_size로 테스트셋의 비율을 정한다. 그리고 테스트셋을 랜덤으로 정하는데 사용하는 seed값을 random_state에 넣는다.\n","random_state를 그대로 두면 받아둔 데이터셋의 뒷부분을 테스트셋으로 사용한다.\n","그리고 test_size만 정의하면 나머지는 다 train_size가 된다.\n","\n","그리고 반환값은 리스트로 반환되기에, ` X_train, X_test, y_train, y_test = train_test_split(...)`형태로 반환값을 받을 수 있다. 외워두자.\n","\n","이렇게 데이터를 나눠놨으면 딥러닝 모델의 학습도 `model.fit(X_train, Y_train, epochs=130, batch_size=5)`와 같이 학습셋으로 한정하자."]},{"cell_type":"code","metadata":{"id":"7LrtU4kOAuec","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623941650648,"user_tz":-540,"elapsed":6811,"user":{"displayName":"공대생지식창고","photoUrl":"","userId":"09343926758650734120"}},"outputId":"11c4621a-92d3-4012-98e5-5607c8b476db"},"source":["# 학습 셋과 테스트 셋의 구분\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=seed)\n","\n","model = Sequential()\n","model.add(Dense(24,  input_dim=60, activation='relu'))\n","model.add(Dense(10, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='mean_squared_error',\n","            optimizer='adam',\n","            metrics=['accuracy'])\n","\n","# 학습셋을 이용해서 딥러닝 모델을 학습한다.\n","model.fit(X_train, Y_train, epochs=130, batch_size=5)\n","\n","# 테스트셋에 모델 적용\n","print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/130\n","145/145 [==============================] - 0s 845us/step - loss: 0.2486 - accuracy: 0.5379\n","Epoch 2/130\n","145/145 [==============================] - 0s 269us/step - loss: 0.2344 - accuracy: 0.5931\n","Epoch 3/130\n","145/145 [==============================] - 0s 322us/step - loss: 0.2233 - accuracy: 0.7241\n","Epoch 4/130\n","145/145 [==============================] - 0s 268us/step - loss: 0.2125 - accuracy: 0.6966\n","Epoch 5/130\n","145/145 [==============================] - 0s 319us/step - loss: 0.2040 - accuracy: 0.7310\n","Epoch 6/130\n","145/145 [==============================] - 0s 412us/step - loss: 0.1969 - accuracy: 0.7793\n","Epoch 7/130\n","145/145 [==============================] - 0s 261us/step - loss: 0.1877 - accuracy: 0.7655\n","Epoch 8/130\n","145/145 [==============================] - 0s 275us/step - loss: 0.1772 - accuracy: 0.7379\n","Epoch 9/130\n","145/145 [==============================] - 0s 254us/step - loss: 0.1660 - accuracy: 0.7793\n","Epoch 10/130\n","145/145 [==============================] - 0s 287us/step - loss: 0.1599 - accuracy: 0.8000\n","Epoch 11/130\n","145/145 [==============================] - 0s 247us/step - loss: 0.1540 - accuracy: 0.8276\n","Epoch 12/130\n","145/145 [==============================] - 0s 277us/step - loss: 0.1559 - accuracy: 0.7586\n","Epoch 13/130\n","145/145 [==============================] - 0s 269us/step - loss: 0.1471 - accuracy: 0.8276\n","Epoch 14/130\n","145/145 [==============================] - 0s 273us/step - loss: 0.1386 - accuracy: 0.8345\n","Epoch 15/130\n","145/145 [==============================] - 0s 331us/step - loss: 0.1348 - accuracy: 0.8483\n","Epoch 16/130\n","145/145 [==============================] - 0s 319us/step - loss: 0.1308 - accuracy: 0.8276\n","Epoch 17/130\n","145/145 [==============================] - 0s 309us/step - loss: 0.1285 - accuracy: 0.8483\n","Epoch 18/130\n","145/145 [==============================] - 0s 293us/step - loss: 0.1257 - accuracy: 0.8621\n","Epoch 19/130\n","145/145 [==============================] - 0s 264us/step - loss: 0.1235 - accuracy: 0.8483\n","Epoch 20/130\n","145/145 [==============================] - 0s 303us/step - loss: 0.1189 - accuracy: 0.8690\n","Epoch 21/130\n","145/145 [==============================] - 0s 279us/step - loss: 0.1226 - accuracy: 0.8552\n","Epoch 22/130\n","145/145 [==============================] - 0s 332us/step - loss: 0.1167 - accuracy: 0.8276\n","Epoch 23/130\n","145/145 [==============================] - 0s 284us/step - loss: 0.1147 - accuracy: 0.8552\n","Epoch 24/130\n","145/145 [==============================] - 0s 306us/step - loss: 0.1097 - accuracy: 0.8621\n","Epoch 25/130\n","145/145 [==============================] - 0s 306us/step - loss: 0.1077 - accuracy: 0.8621\n","Epoch 26/130\n","145/145 [==============================] - 0s 279us/step - loss: 0.1069 - accuracy: 0.8690\n","Epoch 27/130\n","145/145 [==============================] - 0s 267us/step - loss: 0.1037 - accuracy: 0.8621\n","Epoch 28/130\n","145/145 [==============================] - 0s 276us/step - loss: 0.1062 - accuracy: 0.8621\n","Epoch 29/130\n","145/145 [==============================] - 0s 316us/step - loss: 0.1007 - accuracy: 0.8828\n","Epoch 30/130\n","145/145 [==============================] - 0s 293us/step - loss: 0.1075 - accuracy: 0.8621\n","Epoch 31/130\n","145/145 [==============================] - 0s 263us/step - loss: 0.1003 - accuracy: 0.8621\n","Epoch 32/130\n","145/145 [==============================] - 0s 248us/step - loss: 0.0995 - accuracy: 0.8759\n","Epoch 33/130\n","145/145 [==============================] - 0s 305us/step - loss: 0.0942 - accuracy: 0.8966\n","Epoch 34/130\n","145/145 [==============================] - 0s 262us/step - loss: 0.0949 - accuracy: 0.8690\n","Epoch 35/130\n","145/145 [==============================] - 0s 298us/step - loss: 0.0938 - accuracy: 0.8690\n","Epoch 36/130\n","145/145 [==============================] - 0s 278us/step - loss: 0.0945 - accuracy: 0.8621\n","Epoch 37/130\n","145/145 [==============================] - 0s 260us/step - loss: 0.0940 - accuracy: 0.8897\n","Epoch 38/130\n","145/145 [==============================] - 0s 251us/step - loss: 0.0855 - accuracy: 0.8966\n","Epoch 39/130\n","145/145 [==============================] - 0s 260us/step - loss: 0.0843 - accuracy: 0.8897\n","Epoch 40/130\n","145/145 [==============================] - 0s 272us/step - loss: 0.0807 - accuracy: 0.8897\n","Epoch 41/130\n","145/145 [==============================] - 0s 266us/step - loss: 0.0791 - accuracy: 0.8966\n","Epoch 42/130\n","145/145 [==============================] - 0s 264us/step - loss: 0.0758 - accuracy: 0.8897\n","Epoch 43/130\n","145/145 [==============================] - 0s 310us/step - loss: 0.0747 - accuracy: 0.9034\n","Epoch 44/130\n","145/145 [==============================] - 0s 283us/step - loss: 0.0740 - accuracy: 0.9103\n","Epoch 45/130\n","145/145 [==============================] - 0s 273us/step - loss: 0.0730 - accuracy: 0.8828\n","Epoch 46/130\n","145/145 [==============================] - 0s 262us/step - loss: 0.0714 - accuracy: 0.9103\n","Epoch 47/130\n","145/145 [==============================] - 0s 272us/step - loss: 0.0750 - accuracy: 0.8966\n","Epoch 48/130\n","145/145 [==============================] - 0s 353us/step - loss: 0.0628 - accuracy: 0.9448\n","Epoch 49/130\n","145/145 [==============================] - 0s 302us/step - loss: 0.0663 - accuracy: 0.9103\n","Epoch 50/130\n","145/145 [==============================] - 0s 283us/step - loss: 0.0669 - accuracy: 0.9241\n","Epoch 51/130\n","145/145 [==============================] - 0s 289us/step - loss: 0.0607 - accuracy: 0.9379\n","Epoch 52/130\n","145/145 [==============================] - 0s 303us/step - loss: 0.0586 - accuracy: 0.9310\n","Epoch 53/130\n","145/145 [==============================] - 0s 272us/step - loss: 0.0575 - accuracy: 0.9448\n","Epoch 54/130\n","145/145 [==============================] - 0s 249us/step - loss: 0.0545 - accuracy: 0.9586\n","Epoch 55/130\n","145/145 [==============================] - 0s 299us/step - loss: 0.0525 - accuracy: 0.9517\n","Epoch 56/130\n","145/145 [==============================] - 0s 262us/step - loss: 0.0511 - accuracy: 0.9448\n","Epoch 57/130\n","145/145 [==============================] - 0s 253us/step - loss: 0.0511 - accuracy: 0.9379\n","Epoch 58/130\n","145/145 [==============================] - 0s 240us/step - loss: 0.0492 - accuracy: 0.9586\n","Epoch 59/130\n","145/145 [==============================] - 0s 249us/step - loss: 0.0486 - accuracy: 0.9517\n","Epoch 60/130\n","145/145 [==============================] - 0s 255us/step - loss: 0.0490 - accuracy: 0.9517\n","Epoch 61/130\n","145/145 [==============================] - 0s 323us/step - loss: 0.0436 - accuracy: 0.9586\n","Epoch 62/130\n","145/145 [==============================] - 0s 299us/step - loss: 0.0444 - accuracy: 0.9517\n","Epoch 63/130\n","145/145 [==============================] - 0s 289us/step - loss: 0.0403 - accuracy: 0.9586\n","Epoch 64/130\n","145/145 [==============================] - 0s 302us/step - loss: 0.0413 - accuracy: 0.9655\n","Epoch 65/130\n","145/145 [==============================] - 0s 253us/step - loss: 0.0420 - accuracy: 0.9655\n","Epoch 66/130\n","145/145 [==============================] - 0s 290us/step - loss: 0.0468 - accuracy: 0.9586\n","Epoch 67/130\n","145/145 [==============================] - 0s 327us/step - loss: 0.0344 - accuracy: 0.9793\n","Epoch 68/130\n","145/145 [==============================] - 0s 288us/step - loss: 0.0357 - accuracy: 0.9793\n","Epoch 69/130\n","145/145 [==============================] - 0s 282us/step - loss: 0.0318 - accuracy: 0.9793\n","Epoch 70/130\n","145/145 [==============================] - 0s 268us/step - loss: 0.0318 - accuracy: 0.9724\n","Epoch 71/130\n","145/145 [==============================] - 0s 275us/step - loss: 0.0324 - accuracy: 0.9862\n","Epoch 72/130\n","145/145 [==============================] - 0s 266us/step - loss: 0.0305 - accuracy: 0.9724\n","Epoch 73/130\n","145/145 [==============================] - 0s 320us/step - loss: 0.0298 - accuracy: 0.9862\n","Epoch 74/130\n","145/145 [==============================] - 0s 332us/step - loss: 0.0350 - accuracy: 0.9655\n","Epoch 75/130\n","145/145 [==============================] - 0s 304us/step - loss: 0.0320 - accuracy: 0.9655\n","Epoch 76/130\n","145/145 [==============================] - 0s 323us/step - loss: 0.0274 - accuracy: 0.9655\n","Epoch 77/130\n","145/145 [==============================] - 0s 273us/step - loss: 0.0263 - accuracy: 0.9862\n","Epoch 78/130\n","145/145 [==============================] - 0s 280us/step - loss: 0.0270 - accuracy: 0.9793\n","Epoch 79/130\n","145/145 [==============================] - 0s 285us/step - loss: 0.0240 - accuracy: 0.9862\n","Epoch 80/130\n","145/145 [==============================] - 0s 300us/step - loss: 0.0248 - accuracy: 0.9862\n","Epoch 81/130\n","145/145 [==============================] - 0s 319us/step - loss: 0.0250 - accuracy: 0.9862\n","Epoch 82/130\n","145/145 [==============================] - 0s 278us/step - loss: 0.0218 - accuracy: 0.9931\n","Epoch 83/130\n","145/145 [==============================] - 0s 247us/step - loss: 0.0205 - accuracy: 1.0000\n","Epoch 84/130\n","145/145 [==============================] - 0s 304us/step - loss: 0.0206 - accuracy: 0.9931\n","Epoch 85/130\n","145/145 [==============================] - 0s 282us/step - loss: 0.0222 - accuracy: 0.9931\n","Epoch 86/130\n","145/145 [==============================] - 0s 327us/step - loss: 0.0188 - accuracy: 0.9931\n","Epoch 87/130\n","145/145 [==============================] - 0s 266us/step - loss: 0.0192 - accuracy: 1.0000\n","Epoch 88/130\n","145/145 [==============================] - 0s 263us/step - loss: 0.0187 - accuracy: 0.9862\n","Epoch 89/130\n","145/145 [==============================] - 0s 269us/step - loss: 0.0180 - accuracy: 0.9862\n","Epoch 90/130\n","145/145 [==============================] - 0s 307us/step - loss: 0.0164 - accuracy: 0.9931\n","Epoch 91/130\n","145/145 [==============================] - 0s 293us/step - loss: 0.0244 - accuracy: 0.9793\n","Epoch 92/130\n","145/145 [==============================] - 0s 298us/step - loss: 0.0198 - accuracy: 0.9862\n","Epoch 93/130\n","145/145 [==============================] - 0s 266us/step - loss: 0.0164 - accuracy: 0.9862\n","Epoch 94/130\n","145/145 [==============================] - 0s 268us/step - loss: 0.0157 - accuracy: 0.9931\n","Epoch 95/130\n","145/145 [==============================] - 0s 339us/step - loss: 0.0173 - accuracy: 0.9862\n","Epoch 96/130\n","145/145 [==============================] - 0s 276us/step - loss: 0.0196 - accuracy: 0.9793\n","Epoch 97/130\n","145/145 [==============================] - 0s 310us/step - loss: 0.0129 - accuracy: 0.9931\n","Epoch 98/130\n","145/145 [==============================] - 0s 344us/step - loss: 0.0125 - accuracy: 1.0000\n","Epoch 99/130\n","145/145 [==============================] - 0s 303us/step - loss: 0.0133 - accuracy: 0.9931\n","Epoch 100/130\n","145/145 [==============================] - 0s 311us/step - loss: 0.0159 - accuracy: 0.9931\n","Epoch 101/130\n","145/145 [==============================] - 0s 271us/step - loss: 0.0129 - accuracy: 0.9862\n","Epoch 102/130\n","145/145 [==============================] - 0s 260us/step - loss: 0.0120 - accuracy: 0.9931\n","Epoch 103/130\n","145/145 [==============================] - 0s 284us/step - loss: 0.0106 - accuracy: 1.0000\n","Epoch 104/130\n","145/145 [==============================] - 0s 302us/step - loss: 0.0112 - accuracy: 0.9931\n","Epoch 105/130\n","145/145 [==============================] - 0s 329us/step - loss: 0.0108 - accuracy: 0.9931\n","Epoch 106/130\n","145/145 [==============================] - 0s 323us/step - loss: 0.0137 - accuracy: 1.0000\n","Epoch 107/130\n","145/145 [==============================] - 0s 273us/step - loss: 0.0102 - accuracy: 1.0000\n","Epoch 108/130\n","145/145 [==============================] - 0s 281us/step - loss: 0.0106 - accuracy: 1.0000\n","Epoch 109/130\n","145/145 [==============================] - 0s 287us/step - loss: 0.0118 - accuracy: 0.9931\n","Epoch 110/130\n","145/145 [==============================] - 0s 258us/step - loss: 0.0123 - accuracy: 0.9931\n","Epoch 111/130\n","145/145 [==============================] - 0s 272us/step - loss: 0.0097 - accuracy: 0.9931\n","Epoch 112/130\n","145/145 [==============================] - 0s 343us/step - loss: 0.0075 - accuracy: 1.0000\n","Epoch 113/130\n","145/145 [==============================] - 0s 276us/step - loss: 0.0078 - accuracy: 1.0000\n","Epoch 114/130\n","145/145 [==============================] - 0s 270us/step - loss: 0.0093 - accuracy: 1.0000\n","Epoch 115/130\n","145/145 [==============================] - 0s 264us/step - loss: 0.0065 - accuracy: 1.0000\n","Epoch 116/130\n","145/145 [==============================] - 0s 310us/step - loss: 0.0075 - accuracy: 1.0000\n","Epoch 117/130\n","145/145 [==============================] - 0s 329us/step - loss: 0.0067 - accuracy: 1.0000\n","Epoch 118/130\n","145/145 [==============================] - 0s 284us/step - loss: 0.0059 - accuracy: 1.0000\n","Epoch 119/130\n","145/145 [==============================] - 0s 317us/step - loss: 0.0085 - accuracy: 1.0000\n","Epoch 120/130\n","145/145 [==============================] - 0s 259us/step - loss: 0.0062 - accuracy: 1.0000\n","Epoch 121/130\n","145/145 [==============================] - 0s 263us/step - loss: 0.0076 - accuracy: 1.0000\n","Epoch 122/130\n","145/145 [==============================] - 0s 293us/step - loss: 0.0059 - accuracy: 1.0000\n","Epoch 123/130\n","145/145 [==============================] - 0s 389us/step - loss: 0.0054 - accuracy: 1.0000\n","Epoch 124/130\n","145/145 [==============================] - 0s 278us/step - loss: 0.0064 - accuracy: 1.0000\n","Epoch 125/130\n","145/145 [==============================] - 0s 274us/step - loss: 0.0050 - accuracy: 1.0000\n","Epoch 126/130\n","145/145 [==============================] - 0s 254us/step - loss: 0.0053 - accuracy: 1.0000\n","Epoch 127/130\n","145/145 [==============================] - 0s 258us/step - loss: 0.0071 - accuracy: 1.0000\n","Epoch 128/130\n","145/145 [==============================] - 0s 290us/step - loss: 0.0071 - accuracy: 0.9931\n","Epoch 129/130\n","145/145 [==============================] - 0s 291us/step - loss: 0.0053 - accuracy: 1.0000\n","Epoch 130/130\n","145/145 [==============================] - 0s 282us/step - loss: 0.0049 - accuracy: 1.0000\n","63/63 [==============================] - 0s 485us/step\n","\n"," Test Accuracy: 0.7937\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_siDgzq7aAU0"},"source":[""],"execution_count":null,"outputs":[]}]}